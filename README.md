# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**
A summary of the problem statement
The dataset is a CSV file containing 32950 rows and 21 columns, showing personal data (age, job, marital status, etc), previous campaings data, and social and economic context data, of potential customers for a telephone marketing campaign at a portuguese bank. The goal is to predict whether the customer will contract a bank service or product.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**
How the problem was solved
We tried two approaches: a logistic regression model with hyperparameters tuned using Hyperdrive, and a model generated by AutoML. In both cases, the goal was to get the highest accuracy.
Thus, the best model was ..., which reached a X % accuracy.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**
Explanation of the architecture, data, hyperparameters, and classification algorithm
The pipeline is executed and controlled using a Jupyter notebook.
An experiment and a computing cluster were setup for training and testing the models generated by Hyperdrive. The cluster has a maximum of 4 nodes and its size is Standard_D2_V2.

A Sci-kit learn estimator was setup, using the train.py script.
The dataset is first cleaned (null values removed) and some columns (job, contact, education) are one-hot encoded, resulting in 18 additional columns. The dataset is then split in training (80%) and testing(20%) sets. Later, the model is trained using the Logistic Regression algorithm, with hyperparameters C (Inverse of regularization strength) and max_iter (maximun number of iterations to converge) being determined using Hyperdrive. Finally, the model are tested and compared using the Accuracy as benchmarking metric.

The Hyperdrive configuration uses the estimator, parameter sampler, early stopping policy, and is setup to run a maximun of 20 runs, and a maximum of 4 concurrent nodes, given that the cluster has only 4 nodes.

Finally, the best run/performing model (highest accuracy), using the hyperparameters determined by Hyperdrive, is downloaded and registered in Azure ML.

The Logistic Regression algorithm is used for classification tasks, like predicting whether an email message is spam or not, or any binary or categorical result. It is similar to Linear Regression, but it uses the Sigmoid activation function (exponential), instead of the thresholds used in linear regression. In this project, we are using the simplest version of logistic regression: the binary logistic regression, because we want to predict if a customer will contract a bank product/service during a telephone marketing campaign.
The sklearn python library provides this algorithm.


**What are the benefits of the parameter sampler you chose?**
Explanation of the rationale for choosing a particular parameter sampler
The RandomParameterSampling parameter sampler was used because it usually yiedls similar results to the Grid Sampler (search for all the possible combinations) and Bayesian Sampler (using previous models to improve the next one), and it requires less computing time, so it is cheaper also. I used a uniform distribution sampler for the C parameter, because it is a continuous value. And a choice sampler for the max_iter parameter, since it is an integer, discrete value.

**What are the benefits of the early stopping policy you chose?**
Explanation of the rationale for choosing a particular early stopping policy
The BanditPolicy was used as early stopping policy, to avoid wasting computing time when the model performance is not improving. The performance is evaluated every 2 iterations, with a slack_factor of 0.1, which represents the ratio used to calculate the distance from the best performing run. A run is a version of the model with specific values for the hyperparameters.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**
Description of the model and hyperparameters produced by AutoML

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**
Comparison of the models and their performance

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**
Identification of areas to improve the outcome

## Proof of cluster clean up
**If you did not delete your compute cluster in the code, please complete this section. Otherwise, delete this section.**
**Image of cluster marked for deletion**
Proof of cluster cleanup if not included in the notebook
