# Optimizing an ML Pipeline in Azure

## Overview
This project is part of the Udacity Azure ML Nanodegree.
In this project, we build and optimize an Azure ML pipeline using the Python SDK and a provided Scikit-learn model.
This model is then compared to an Azure AutoML run.

## Summary
**In 1-2 sentences, explain the problem statement: e.g "This dataset contains data about... we seek to predict..."**

The dataset is a CSV file containing 32950 rows and 21 columns, showing personal data (age, job, marital status, etc), previous campaings data, and social and economic context data, of potential customers for a telephone marketing campaign at a portuguese bank. The goal is to predict whether the customer will contract a bank service or product.

**In 1-2 sentences, explain the solution: e.g. "The best performing model was a ..."**

We tried two approaches: a logistic regression model with hyperparameters tuned using Hyperdrive, and a model generated by AutoML. In both cases, the goal was to get the highest accuracy.
Thus, the best model was generated by Azure AutoML, using the Voting Ensemble algorithm, which reached a 91.53 % of accuracy.

## Scikit-learn Pipeline
**Explain the pipeline architecture, including data, hyperparameter tuning, and classification algorithm.**

The pipeline is executed and controlled using a Jupyter notebook.
An experiment and a computing cluster were setup for training and testing the models generated by Hyperdrive. The cluster has a maximum of 4 nodes and its size is Standard_D2_V2.

A Sci-kit learn estimator was setup, using the train.py script.
The dataset is first cleaned (null values removed) and some columns (job, contact, education) are one-hot encoded, resulting in 18 additional columns. The dataset is then split in training (80%) and testing(20%) sets. Later, the model is trained using the Logistic Regression algorithm, with hyperparameters C (Inverse of regularization strength) and max_iter (maximun number of iterations to converge) being determined using Hyperdrive. Finally, the models are tested and compared using the Accuracy as benchmarking metric.

The Hyperdrive configuration uses the estimator, parameter sampler, early stopping policy, and is setup to run a maximun of 4 runs, and a maximum of 4 concurrent nodes, given that the cluster has only 4 nodes.

Finally, the best run/performing model (highest accuracy), using the hyperparameters determined by Hyperdrive, is downloaded and registered in Azure ML. The best model generated by Hyperdrive got a 90.97 % of accuracy, with hyperparameters max_iter = 200 and regularization strength = 0.8858464414859172

Best Run Id:  HD_c169f4e9-e4aa-46bb-8e58-f076f33de94a_0
```
{'Regularization Strength:': 0.8858464414859172, 
'Max iterations:': 200, 
'Accuracy': 0.909711684370258}
```

Execution Summary
=================
RunId: HD_c169f4e9-e4aa-46bb-8e58-f076f33de94a
Web View: https://ml.azure.com/experiments/bank-marketing-hyperdrive-2/runs/HD_c169f4e9-e4aa-46bb-8e58-f076f33de94a?wsid=/subscriptions/8e713106-916f-4177-890e-435b90d7adc4/resourcegroups/aml-quickstarts-127439/workspaces/quick-starts-ws-127439
```
{'runId': 'HD_c169f4e9-e4aa-46bb-8e58-f076f33de94a',
 'target': 'simba-cluster',
 'status': 'Completed',
 'startTimeUtc': '2020-11-23T00:44:36.682588Z',
 'endTimeUtc': '2020-11-23T00:54:28.751307Z',
 'properties': {'primary_metric_config': '{"name": "Accuracy", "goal": "maximize"}',
  'resume_from': 'null',
  'runTemplate': 'HyperDrive',
  'azureml.runsource': 'hyperdrive',
  'platform': 'AML',
  'ContentSnapshotId': '992fbf64-73f8-400c-be2d-a0f85d704d25',
  'score': '0.909711684370258',
  'best_child_run_id': 'HD_c169f4e9-e4aa-46bb-8e58-f076f33de94a_0',
  'best_metric_status': 'Succeeded'},
 'inputDatasets': [],
 'outputDatasets': [],
 'logFiles': {'azureml-logs/hyperdrive.txt': 'https://mlstrg127439.blob.core.windows.net/azureml/ExperimentRun/dcid.HD_c169f4e9-e4aa-46bb-8e58-f076f33de94a/azureml-logs/hyperdrive.txt?sv=2019-02-02&sr=b&sig=3ST0%2BZUfgxKQDXZDUxT%2Be0vJzmEKMTUOHeBmeJYl1d0%3D&st=2020-11-23T00%3A44%3A31Z&se=2020-11-23T08%3A54%3A31Z&sp=r'}}
```

The Logistic Regression algorithm is used for classification tasks, like predicting whether an email message is spam or not, or any binary or categorical result. It is similar to Linear Regression, but it uses the Sigmoid activation function (exponential), instead of the thresholds used in linear regression. In this project, we are using the simplest version of logistic regression: the binary logistic regression, because we want to predict if a customer will contract a bank product/service during a telephone marketing campaign.
The sklearn python library provides this algorithm.

Finally, the computing cluster is deleted to avoid wasting resources.


**What are the benefits of the parameter sampler you chose?**

The RandomParameterSampling parameter sampler was used because it usually yiedls similar results to the Grid Sampler (search for all the possible combinations) and Bayesian Sampler (using previous models to improve the next one), and it requires less computing time, so it is cheaper also. I used a uniform distribution sampler for the C parameter, because it is a continuous value. And a choice sampler for the max_iter parameter, since it is an integer, discrete value.

**What are the benefits of the early stopping policy you chose?**

The BanditPolicy was used as early stopping policy, to avoid wasting computing time when the model performance is not improving. The performance is evaluated every 2 iterations, with a slack_factor of 0.1, which represents the ratio used to calculate the distance from the best performing run. A run is a version of the model with specific values for the hyperparameters.

## AutoML
**In 1-2 sentences, describe the model and hyperparameters generated by AutoML.**

The best model generated by Azure AutoML was the Voting Ensemble algorithm, reaching an accuracy of 91.53 %, obtained in Run 81, with a training time of 1 minute 12 seconds. It used the following models:

```
"ensembled_algorithms": "['LightGBM', 'XGBoostClassifier', 'XGBoostClassifier', 'XGBoostClassifier', 'XGBoostClassifier', 'SGD', 'XGBoostClassifier', 'XGBoostClassifier', 'SGD']",
```

![AutoML experiment results](https://github.com/jhonatantirado/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/images/AutoMLRanking.png)


```
Best Run Id:  AutoML_263d3151-5dc6-46d2-a5d3-f798006c5af8_76
Run(Experiment: bank-marketing-automl,
Id: AutoML_263d3151-5dc6-46d2-a5d3-f798006c5af8_76,
Type: azureml.scriptrun,
Status: Completed)
Pipeline(memory=None,
         steps=[('datatransformer',
                 DataTransformer(enable_dnn=None, enable_feature_sweeping=None,
                                 feature_sweeping_config=None,
                                 feature_sweeping_timeout=None,
                                 featurization_config=None, force_text_dnn=None,
                                 is_cross_validation=None,
                                 is_onnx_compatible=None, logger=None,
                                 observer=None, task=None, working_dir=None)),
                ('prefittedsoftvotingclassifier',...
                                                                                                  loss='modified_huber',
                                                                                                  max_iter=1000,
                                                                                                  n_jobs=1,
                                                                                                  penalty='none',
                                                                                                  power_t=0.1111111111111111,
                                                                                                  random_state=None,
                                                                                                  tol=0.001))],
                                                                     verbose=False))],
                                               flatten_transform=None,
                                               weights=[0.13333333333333333,
                                                        0.13333333333333333,
                                                        0.13333333333333333,
                                                        0.06666666666666667,
                                                        0.13333333333333333,
                                                        0.13333333333333333,
                                                        0.06666666666666667,
                                                        0.06666666666666667,
                                                        0.13333333333333333]))],
         verbose=False)
{'weighted_accuracy': 0.9610915589748967, 'matthews_correlation': 0.529907872371117, 'recall_score_weighted': 0.9153641881638848, 'precision_score_macro': 0.8026299752952475, 'f1_score_weighted': 0.9097234886869598, 'precision_score_weighted': 0.9076084638625477, 'f1_score_macro': 0.7605499022782608, 'average_precision_score_weighted': 0.953840886411121, 'balanced_accuracy': 0.7323083034095487, 'AUC_weighted': 0.945379968896203, 'f1_score_micro': 0.9153641881638848, 'norm_macro_recall': 0.46461660681909733, 'recall_score_macro': 0.7323083034095487, 'precision_score_micro': 0.9153641881638848, 'average_precision_score_macro': 0.8196573160306446, 'accuracy': 0.9153641881638848, 'recall_score_micro': 0.9153641881638848, 'average_precision_score_micro': 0.9807673331214697, 'AUC_macro': 0.945379968896203, 'AUC_micro': 0.9799437489781961, 'log_loss': 0.19361719793122611, 'accuracy_table': 'aml://artifactId/ExperimentRun/dcid.AutoML_263d3151-5dc6-46d2-a5d3-f798006c5af8_76/accuracy_table', 'confusion_matrix': 'aml://artifactId/ExperimentRun/dcid.AutoML_263d3151-5dc6-46d2-a5d3-f798006c5af8_76/confusion_matrix'}
Model(workspace=Workspace.create(name='quick-starts-ws-127467', subscription_id='94e14ad4-bf97-47e8-aae0-f9b85a7befa8', resource_group='aml-quickstarts-127467'), name=bank-marketing-automl-model, id=bank-marketing-automl-model:1, version=1, tags={'Method': 'AutoML'}, properties={'accuracy': '0.9153641881638848'})
```

Also, we found out that the most important feature to determine the outcome of the best AutoML model is the "duration" of the phone call. See image below.

![AutoML feature importance for the best model](https://github.com/jhonatantirado/nd00333_AZMLND_Optimizing_a_Pipeline_in_Azure-Starter_Files/blob/master/images/AutoMLBestModelFeaturesImportance.png)

## Pipeline comparison
**Compare the two models and their performance. What are the differences in accuracy? In architecture? If there was a difference, why do you think there was one?**

The AutoML model experiment was executed and controlled within the same Jupyter notebook as the Logistic Regression/Hyperdrive one.
The same dataset was used, cleaned, one-hot encoded, and split. An experiment and computing cluster, similar to the Logistic Regression model, were setup. The Accuracy was used as benchmarking metric.
The AutoML experiment was configured to run a classification task, with a maximum of 4 concurrent iterations (the computing cluster has 4 nodes), and 2 cross validation groups.
Finally, the best performing model was registered in Azure ML, and the computing cluster was deleted.

As we can see, the accuracy of the best performing models is 91.53 %, using the Voting Ensemble approach, which relies on multiple models instead of a single one, to classify an instance or predict an outcome.
The biggest difference is that the Hyperdrive experiment uses only an algorithm and searches for the best hyperparameters, while the AutoML experiment tries different algorithms and hyperparameters. Other than that, the workflow is similar. Also, the train.py script was only used in the Hyperdrive experiment.

## Future work
**What are some areas of improvement for future experiments? Why might these improvements help the model?**

1. Use feature engineering techniques to identify the most relevant columns for training the Logistic Regression model. This could improve accuracy and reduce training time.
2. Use the Azure ML Explainability tool to understand why the models yield the results they do.
3. Use Grid and Bayesian sampling to determine the hyperparameters for the Hyperdrive experiment. It could be more expensive, but it could generate a better model.
4. Use more cross validation groups to reduce the model bias, avoid overfitting and make sure the model can generalize on new data.
5. Do not use an early stopping policy so the experiment can run longer. Maybe it will find a better model. We can do this if we have a great budget.
6. Deploy the model as inference endpoints to be consumed by mobile or web applications.
